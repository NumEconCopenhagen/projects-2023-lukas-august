from types import SimpleNamespace

import numpy as np
from scipy import optimize

import pandas as pd
import matplotlib.pyplot as plt

class HouseholdSpecializationModelClass:

    def __init__(self):
        """ setup model """

        # a. create namespaces
        par = self.par = SimpleNamespace()
        sol = self.sol = SimpleNamespace()

        # b. preferences
        par.rho = 2.0
        par.nu = 0.001
        par.epsilon = 1.0
        par.omega = 0.5

        # c. household production
        par.alpha = 0.5
        par.sigma = 1.0

        # d. wages
        par.wM = 1.0
        par.wF = 1.0
        par.wF_vec = np.linspace(0.8,1.2,5)

        # e. targets
        par.beta0_target = 0.4
        par.beta1_target = -0.1

        # f. solution
        sol.LM_vec = np.zeros(par.wF_vec.size)
        sol.HM_vec = np.zeros(par.wF_vec.size)
        sol.LF_vec = np.zeros(par.wF_vec.size)
        sol.HF_vec = np.zeros(par.wF_vec.size)

        sol.beta0 = np.nan
        sol.beta1 = np.nan

    def calc_utility(self,LM,HM,LF,HF):
        """ calculate utility """

        par = self.par
        sol = self.sol

        # a. consumption of market goods
        C = par.wM*LM + par.wF*LF

        # b. home production (redifined)
        if par.sigma == 1:
            H = HM**(1-par.alpha)*HF**par.alpha
        else:
            H = ((1-par.alpha)*HM**((par.sigma-1)/par.sigma)+par.alpha*HF**((par.sigma-1)/par.sigma))**(par.sigma/(par.sigma-1))

        # c. total consumption utility
        Q = C**par.omega*H**(1-par.omega)
        utility = np.fmax(Q,1e-8)**(1-par.rho)/(1-par.rho)

        # d. disutlity of work
        epsilon_ = 1+1/par.epsilon
        TM = LM+HM
        TF = LF+HF
        disutility = par.nu*(TM**epsilon_/epsilon_+TF**epsilon_/epsilon_)

        return utility - disutility

    def solve_discrete(self,do_print=False):
        """ solve model discretely """

        par = self.par
        sol = self.sol
        opt = SimpleNamespace()

        # a. all possible choices
        x = np.linspace(0,24,49)
        LM,HM,LF,HF = np.meshgrid(x,x,x,x) # all combinations

        LM = LM.ravel() # vector
        HM = HM.ravel()
        LF = LF.ravel()
        HF = HF.ravel()

        # b. calculate utility
        u = self.calc_utility(LM,HM,LF,HF)

        # c. set to minus infinity if constraint is broken
        I = (LM+HM > 24) | (LF+HF > 24) # | is "or"
        u[I] = -np.inf

        # d. find maximizing argument
        j = np.argmax(u)

        opt.LM = LM[j]
        opt.HM = HM[j]
        opt.LF = LF[j]
        opt.HF = HF[j]

        # e. print
        if do_print:
            for k,v in opt.__dict__.items():
                print(f'{k} = {v:6.4f}')

        return opt

    def solve(self,do_print=False):
        """ solve model continously """
         #Objective function set to minus utility

        par = self.par
        sol = self.sol

        # a. define objective function to maximize
        def objective(x):
            LM,HM,LF,HF = x
            return -self.calc_utility(LM,HM,LF,HF)

        # b. define constraints
        def constraint1(x):
            LM,HM,LF,HF = x
            return 24 - (LM + HM)
        def constraint2(x):
            LM,HM,LF,HF = x
            return 24 - (LF + HF)
        constraints = [{'type': 'ineq', 'fun': constraint1},
                       {'type': 'ineq', 'fun': constraint2}]

        # c. initial guess
        x0 = np.array([12, 12, 12, 12])

        # d. find optimal values
        opt = optimize.minimize(objective, x0, method='Nelder-Mead', constraints=constraints)

        # e. save results
        opt.LM = opt.x[0]
        opt.HM = opt.x[1]
        opt.LF = opt.x[2]
        opt.HF = opt.x[3]

        # f. print
        if do_print:
            for k,v in opt.__dict__.items():
                print(f'{k} = {v:6.4f}')

        return opt

    def solve_wF_vec(self,discrete=False):
        """ solve model for vector of female wages """

        par = self.par
        sol = self.sol

        # a. Loop through vector and solve the (continous) model for each iteration.
        for i, x in enumerate(par.wF_vec) :
            par.wF = x
            out = self.solve()

            # b. Save restult
            sol.LM_vec[i] = out.LM
            sol.LF_vec[i] = out.LF
            sol.HM_vec[i] = out.HM
            sol.HF_vec[i] = out.HF


    def run_regression(self):
        """ run regression """

        par = self.par
        sol = self.sol

        x = np.log(par.wF_vec)
        y = np.log(sol.HF_vec/sol.HM_vec)
        A = np.vstack([np.ones(x.size),x]).T
        sol.beta0,sol.beta1 = np.linalg.lstsq(A,y,rcond=None)[0]

    def estimate(self,alpha=None,sigma=None):
        """ estimate alpha and sigma """

        par = self.par
        sol = self.sol

        # a. Objective function
        def objective(x, self):

            # Set alpha and sigma
            par.alpha = x[0]
            par.sigma = x[1]

            # Solve for female wages vector
            self.solve_wF_vec()

            # Run regression
            self.run_regression()

            # Return the function which should be minimized
            return (0.4-sol.beta0)**2+(-0.1-sol.beta1)**2

        # b. Initial guess
        x0 = np.array([0.5, 0.5])

        # c. Set interval for alpha and sigma
        bounds = [(0,1), (0,10)]

        # d. Use scipy's minimize to find the value of sigma and alpha that minimizes the objective function
        result = optimize.minimize(objective, x0, args = self, method = 'Nelder-Mead', bounds = bounds)

    def estimate_alternative(self,sigma=None):
        """ estimate sigma while alpha is fixed at 0.5 """

        par = self.par
        sol = self.sol

        # a. Objective function
        def objective(x, self):

            # Set sigma
            par.sigma = x[0]

            # Solve for female wages vector
            self.solve_wF_vec()

            # Run regression
            self.run_regression()

            # Return the function which should be minimized
            return (0.4-sol.beta0)**2+(-0.1-sol.beta1)**2

        # b. Initial guess
        x0 = np.array([0.5])

        # c. Set interval for sigma
        bounds = [(0,10)]

        # d. Use scipy's minimize to find the value of sigma that minimizes the objective function, while holding alpha fixed at 0.5
        result = optimize.minimize(objective, x0, args = (self), method = 'Nelder-Mead', bounds=bounds)
